#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –∏ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è API –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
"""

import asyncio
import json
import time
from statistics import mean, median, stdev
from typing import List, Dict, Any

import httpx
import matplotlib.pyplot as plt


class APIBenchmark:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ API."""

    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results: List[Dict[str, Any]] = []

    async def single_request(
        self, client: httpx.AsyncClient, question: str
    ) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∏ –∏–∑–º–µ—Ä—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏."""
        start_time = time.perf_counter()

        try:
            response = await client.post(
                f"{self.base_url}/question", json={"text": question}, timeout=30.0
            )

            end_time = time.perf_counter()
            response_time = end_time - start_time

            return {
                "success": True,
                "status_code": response.status_code,
                "response_time": response_time,
                "question_length": len(question),
                "response_length": len(response.text)
                if response.status_code == 200
                else 0,
                "headers": dict(response.headers),
                "error": None,
            }

        except Exception as e:
            end_time = time.perf_counter()
            return {
                "success": False,
                "status_code": 0,
                "response_time": end_time - start_time,
                "question_length": len(question),
                "response_length": 0,
                "headers": {},
                "error": str(e),
            }

    async def concurrent_benchmark(
        self, questions: List[str], concurrency: int = 5
    ) -> None:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
        print(f"üöÄ –ó–∞–ø—É—Å–∫ benchmark —Å {concurrency} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏...")

        async with httpx.AsyncClient() as client:
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏
            tasks = []
            for i in range(len(questions)):
                question = questions[i % len(questions)]
                task = self.single_request(client, question)
                tasks.append(task)

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                if len(tasks) >= concurrency:
                    results = await asyncio.gather(*tasks)
                    self.results.extend(results)
                    tasks = []

                    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
                    await asyncio.sleep(0.1)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–¥–∞—á–∏
            if tasks:
                results = await asyncio.gather(*tasks)
                self.results.extend(results)

    async def sequential_benchmark(self, questions: List[str]) -> None:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã."""
        print("üîÑ –ó–∞–ø—É—Å–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...")

        async with httpx.AsyncClient() as client:
            for question in questions:
                result = await self.single_request(client, question)
                self.results.append(result)

                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                await asyncio.sleep(0.5)

    def analyze_results(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–æ–≤."""
        if not self.results:
            return {"error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}

        successful = [r for r in self.results if r["success"]]
        failed = [r for r in self.results if not r["success"]]

        if not successful:
            return {"error": "–í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –æ—à–∏–±–∫–æ–π"}

        response_times = [r["response_time"] for r in successful]

        analysis = {
            "total_requests": len(self.results),
            "successful_requests": len(successful),
            "failed_requests": len(failed),
            "success_rate": len(successful) / len(self.results) * 100,
            "response_times": {
                "min": min(response_times),
                "max": max(response_times),
                "mean": mean(response_times),
                "median": median(response_times),
                "std_dev": stdev(response_times) if len(response_times) > 1 else 0,
            },
            "status_codes": {},
            "errors": [],
        }

        # –ü–æ–¥—Å—á–µ—Ç –∫–æ–¥–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤
        for result in self.results:
            code = result["status_code"]
            analysis["status_codes"][code] = analysis["status_codes"].get(code, 0) + 1

        # –°–±–æ—Ä –æ—à–∏–±–æ–∫
        for result in failed:
            if result["error"]:
                analysis["errors"].append(result["error"])

        return analysis

    def print_results(self, analysis: Dict[str, Any]) -> None:
        """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫–æ–Ω—Å–æ–ª—å."""
        print("\n" + "=" * 60)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ BENCHMARK")
        print("=" * 60)

        if "error" in analysis:
            print(f"‚ùå –û—à–∏–±–∫–∞: {analysis['error']}")
            return

        print("üìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {analysis['total_requests']}")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {analysis['successful_requests']}")
        print(f"   –ù–µ—É–¥–∞—á–Ω—ã—Ö: {analysis['failed_requests']}")
        print(f"   –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {analysis['success_rate']:.1f}%")

        rt = analysis["response_times"]
        print("\n‚è±Ô∏è –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (—Å–µ–∫):")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ: {rt['min']:.4f}")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ: {rt['max']:.4f}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ: {rt['mean']:.4f}")
        print(f"   –ú–µ–¥–∏–∞–Ω–∞: {rt['median']:.4f}")
        print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {rt['std_dev']:.4f}")

        print("\nüìã –ö–æ–¥—ã –æ—Ç–≤–µ—Ç–æ–≤:")
        for code, count in analysis["status_codes"].items():
            print(f"   {code}: {count} –∑–∞–ø—Ä–æ—Å–æ–≤")

        if analysis["errors"]:
            print("\n‚ùå –û—à–∏–±–∫–∏:")
            for error in set(analysis["errors"]):
                count = analysis["errors"].count(error)
                print(f"   {error}: {count} —Ä–∞–∑")

    def save_chart(
        self, analysis: Dict[str, Any], filename: str = "results/benchmark_chart.png"
    ) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥—Ä–∞—Ñ–∏–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        if "error" in analysis or not self.results:
            return

        successful = [r for r in self.results if r["success"]]
        response_times = [r["response_time"] for r in successful]

        plt.figure(figsize=(12, 8))

        # –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞
        plt.subplot(2, 2, 1)
        plt.plot(response_times, "b-", alpha=0.7)
        plt.title("–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º")
        plt.xlabel("–ù–æ–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞")
        plt.ylabel("–í—Ä–µ–º—è (—Å–µ–∫)")
        plt.grid(True, alpha=0.3)

        # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞
        plt.subplot(2, 2, 2)
        plt.hist(response_times, bins=20, alpha=0.7, color="green")
        plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞")
        plt.xlabel("–í—Ä–µ–º—è (—Å–µ–∫)")
        plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤")
        plt.grid(True, alpha=0.3)

        # –ì—Ä–∞—Ñ–∏–∫ –∫–æ–¥–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤
        plt.subplot(2, 2, 3)
        codes = list(analysis["status_codes"].keys())
        counts = list(analysis["status_codes"].values())
        plt.bar([str(c) for c in codes], counts, alpha=0.7, color="orange")
        plt.title("–ö–æ–¥—ã –æ—Ç–≤–µ—Ç–æ–≤")
        plt.xlabel("HTTP –∫–æ–¥")
        plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
        plt.grid(True, alpha=0.3)

        # –°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        plt.subplot(2, 2, 4)
        plt.text(0.1, 0.8, f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {analysis['total_requests']}", fontsize=12)
        plt.text(0.1, 0.7, f"–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {analysis['success_rate']:.1f}%", fontsize=12)
        plt.text(
            0.1,
            0.6,
            f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {analysis['response_times']['mean']:.3f}s",
            fontsize=12,
        )
        plt.text(
            0.1,
            0.5,
            f"–ú–µ–¥–∏–∞–Ω–∞: {analysis['response_times']['median']:.3f}s",
            fontsize=12,
        )
        plt.xlim(0, 1)
        plt.ylim(0, 1)
        plt.axis("off")
        plt.title("–°–≤–æ–¥–∫–∞")

        plt.tight_layout()
        plt.savefig(filename, dpi=300, bbox_inches="tight")
        print(f"üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤."""
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    test_questions = [
        "Hello!",
        "How are you?",
        "What is AI?",
        "Tell me a joke",
        "Explain quantum physics",
        "Write a poem about coding",
        "What's the weather like?",
        "Help me with Python",
        "Translate: Bonjour",
        "What is 2+2?",
    ]

    print("üîß –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ API...")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:8000/health", timeout=5.0)
            if response.status_code != 200:
                print("‚ùå API –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω!")
                return
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API: {e}")
        return

    benchmark = APIBenchmark()

    # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç
    print("\n1Ô∏è‚É£ –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç (5 –∑–∞–ø—Ä–æ—Å–æ–≤)...")
    await benchmark.sequential_benchmark(test_questions[:5])

    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç
    print("\n2Ô∏è‚É£ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç (10 –∑–∞–ø—Ä–æ—Å–æ–≤, 3 –ø–æ—Ç–æ–∫–∞)...")
    await benchmark.concurrent_benchmark(test_questions[:10], concurrency=3)

    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    analysis = benchmark.analyze_results()
    benchmark.print_results(analysis)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    try:
        benchmark.save_chart(analysis)
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫: {e}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –æ—Ç—á–µ—Ç–∞
    with open("results/benchmark_report.json", "w", encoding="utf-8") as f:
        json.dump(
            {"analysis": analysis, "raw_results": benchmark.results},
            f,
            indent=2,
            ensure_ascii=False,
        )

    print("\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: results/benchmark_report.json")
    print("‚úÖ –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    asyncio.run(main())
